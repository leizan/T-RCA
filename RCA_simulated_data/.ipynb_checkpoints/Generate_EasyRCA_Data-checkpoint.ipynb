{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b862fbf-d8d2-4014-8b7f-996f632ae182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "# sys.path.append('/home/lzan/Bureau/Dynamic causal graph/root-cause-analysis/EasyRCA/TestEasyRCA_AISTATS2023/')\n",
    "from tqdm import tqdm\n",
    "from generate_data import generate_data_with_parametric_intervention # , generate_data_with_structural_intervention\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45f0ee8f-1395-4787-8038-4df4b034e053",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dict_to_graph(graph_dict, inter_nodes):\n",
    "    # Create an empty directed graph\n",
    "    graph = nx.DiGraph()\n",
    "\n",
    "    # Iterate through the dictionary and add nodes and edges to the graph\n",
    "    for parent, children in graph_dict.items():\n",
    "        # Add the parent node to the graph\n",
    "        graph.add_node(parent)\n",
    "\n",
    "        # Iterate through the children of the parent\n",
    "        for child in children.keys():\n",
    "            # Add the child node to the graph and create a directed edge from parent to child\n",
    "            graph.add_node(child)\n",
    "            if child not in inter_nodes:\n",
    "                graph.add_edge(parent, child)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def generate_historical_data_by_folder_PC(graphs_path, data_path, info_path, n, anomaly_length):\n",
    "    if not os.path.exists(data_path):\n",
    "        # If it doesn't exist, create the folder\n",
    "        os.makedirs(data_path)\n",
    "    # check the existence of data information folder\n",
    "    if not os.path.exists(info_path):\n",
    "        # If it doesn't exist, create the folder\n",
    "        os.makedirs(info_path)\n",
    "\n",
    "    graph_files = [os.path.join(graphs_path, f) for f in os.listdir(graphs_path) if os.path.isfile(os.path.join(graphs_path, f))]\n",
    "\n",
    "    for json_file_path in tqdm(graph_files):\n",
    "        with open(json_file_path, 'r') as json_file:\n",
    "            json_graph = json.load(json_file)\n",
    "\n",
    "        # Convert the loaded JSON data into a NetworkX graph\n",
    "        graph = dict_to_graph(graph_dict=json_graph, inter_nodes=[])\n",
    "\n",
    "        root = []\n",
    "        for node in graph.nodes: \n",
    "            if len(list(graph.predecessors(node)))==0:\n",
    "                root.append(node)\n",
    "        \n",
    "        while True:\n",
    "            intervention_nodes = np.random.choice(graph.nodes,replace=False, size=2)\n",
    "            all_paths = list(nx.all_simple_paths(graph, source=intervention_nodes[0], target=intervention_nodes[1]))\n",
    "            all_paths += list(nx.all_simple_paths(graph, source=intervention_nodes[1], target=intervention_nodes[0]))\n",
    "            nodes_in_same_path = any(intervention_nodes[0] in path and intervention_nodes[1] in path for path in all_paths)\n",
    "            if not nodes_in_same_path:\n",
    "                break\n",
    "\n",
    "        # if nx.has_path(graph, root[0], intervention_node):\n",
    "        #     print(root[0] + ' and ' + intervention_node + \" are in the same path.\")\n",
    "            \n",
    "\n",
    "        data = generate_data_with_parametric_intervention(DAG =graph,n=n, secondInterventionNode=intervention_nodes, rootStartIntervention=n-anomaly_length, rootEndIntervention=n-1)\n",
    "        # data = generate_data_with_structural_intervention(DAG =graph,n=n, secondInterventionNode=intervention_node, rootStartIntervention=n-anomaly_length, rootEndIntervention=n-1)\n",
    "\n",
    "        # root.append(intervention_node)\n",
    "        \n",
    "        info = {'intervention_nodes': list(intervention_nodes), 'anomaly_length': anomaly_length}\n",
    "\n",
    "        data.to_csv(os.path.join(data_path, json_file_path.split('/')[1].replace('graph', 'data').replace('json', 'csv')), index=False)\n",
    "\n",
    "        data_info_path = os.path.join(info_path, json_file_path.split('/')[1].replace('graph', 'info'))\n",
    "        # Save the dictionary as a JSON file\n",
    "        with open(data_info_path, 'w') as json_file:\n",
    "            json.dump(info, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52f5b8d3-e62f-4d30-bb39-d6a0d56e21ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 770.96it/s]\n"
     ]
    }
   ],
   "source": [
    "graphs_path = 'graphs'\n",
    "data_path = os.path.join('EasyRCA', 'Parametric_2', 'data')\n",
    "info_path = os.path.join('EasyRCA','Parametric_2', 'data_info')\n",
    "# data_path = os.path.join('EasyRCA', 'Structual', 'data')\n",
    "# info_path = os.path.join('EasyRCA','Structual', 'data_info')\n",
    "n = 22000\n",
    "anomaly_length = 2000\n",
    "generate_historical_data_by_folder_PC(graphs_path=graphs_path, data_path=data_path, info_path=info_path, n=n, anomaly_length=anomaly_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c075a9-5a67-4608-b30c-8e3234070869",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e15439b-77c0-4329-a27d-fb2cb7db9dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ebfe6e-75d7-4742-9c8f-b3309dcdb261",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c54bd9-f230-40d6-bd8a-cf4eb846ec01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed34487c-0875-46c4-bdce-a3e8539c4f18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "663b0ef9-af6a-4e1e-9c97-498e47ff32f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a and f are in the same path.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/50 [00:28<23:24, 28.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a and b are in the same path.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 2/50 [00:53<20:54, 26.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a and d are in the same path.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [01:17<19:53, 25.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a and c are in the same path.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 3/50 [01:27<22:56, 29.28s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(root[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m intervention_node \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m are in the same path.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     30\u001b[0m     index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 32\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_data_with_parametric_intervention\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDAG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecondInterventionNode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mintervention_node\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrootStartIntervention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrootEndIntervention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Bureau/Dynamic causal graph/root-cause-analysis/EasyRCA/TestEasyRCA_AISTATS2023/generate_data.py:488\u001b[0m, in \u001b[0;36mgenerate_data_with_parametric_intervention\u001b[0;34m(DAG, n, secondInterventionNode, rootStartIntervention, rootEndIntervention)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m orderingNodes[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    486\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m par \u001b[38;5;129;01min\u001b[39;00m DAG\u001b[38;5;241m.\u001b[39mpredecessors(node):\n\u001b[1;32m    487\u001b[0m             \u001b[38;5;66;03m# data[node] = data[node] + data[par].shift(periods=1)\u001b[39;00m\n\u001b[0;32m--> 488\u001b[0m             data[node]\u001b[38;5;241m.\u001b[39mloc[i] \u001b[38;5;241m=\u001b[39m noise[node]\u001b[38;5;241m.\u001b[39mloc[i] \u001b[38;5;241m+\u001b[39m coef_dict[(node, node)] \u001b[38;5;241m*\u001b[39m data[node]\u001b[38;5;241m.\u001b[39mloc[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m coef_dict[(par, node)] \u001b[38;5;241m*\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpar\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mloc[i\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# intervention on root\u001b[39;00m\n\u001b[1;32m    491\u001b[0m data[orderingNodes[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mloc[rootStartIntervention: rootEndIntervention] \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m    492\u001b[0m     np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, size\u001b[38;5;241m=\u001b[39manomaly_size) \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;241m0.1\u001b[39m \u001b[38;5;241m*\u001b[39m data[orderingNodes[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39mloc[rootStartIntervention: rootEndIntervention]\u001b[38;5;241m.\u001b[39mshift(periods\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:3759\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3758\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m-> 3759\u001b[0m     \u001b[43mcheck_deprecated_indexers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3760\u001b[0m     key \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(key)\n\u001b[1;32m   3761\u001b[0m     key \u001b[38;5;241m=\u001b[39m com\u001b[38;5;241m.\u001b[39mapply_if_callable(key, \u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexing.py:2656\u001b[0m, in \u001b[0;36mcheck_deprecated_indexers\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m   2644\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2645\u001b[0m \u001b[38;5;124;03m    Returns\u001b[39;00m\n\u001b[1;32m   2646\u001b[0m \u001b[38;5;124;03m    -------\u001b[39;00m\n\u001b[1;32m   2647\u001b[0m \u001b[38;5;124;03m    bool\u001b[39;00m\n\u001b[1;32m   2648\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2649\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m   2650\u001b[0m         obj\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2651\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2652\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m (obj\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m obj\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   2653\u001b[0m     )\n\u001b[0;32m-> 2656\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_deprecated_indexers\u001b[39m(key) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2657\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Checks if the key is a deprecated indexer.\"\"\"\u001b[39;00m\n\u001b[1;32m   2658\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2659\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mset\u001b[39m)\n\u001b[1;32m   2660\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m   2661\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mset\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   2662\u001b[0m     ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# if not os.path.exists(data_path):\n",
    "# # If it doesn't exist, create the folder\n",
    "#     os.makedirs(data_path)\n",
    "# # check the existence of data information folder\n",
    "# if not os.path.exists(info_path):\n",
    "# # If it doesn't exist, create the folder\n",
    "#     os.makedirs(info_path)\n",
    "\n",
    "n = 22000\n",
    "\n",
    "graph_files = [os.path.join(graphs_path, f) for f in os.listdir(graphs_path) if os.path.isfile(os.path.join(graphs_path, f))]\n",
    "index = 0\n",
    "\n",
    "for json_file_path in tqdm(graph_files):\n",
    "    with open(json_file_path, 'r') as json_file:\n",
    "        json_graph = json.load(json_file)\n",
    "\n",
    "    # Convert the loaded JSON data into a NetworkX graph\n",
    "    graph = dict_to_graph(graph_dict=json_graph, inter_nodes=[])\n",
    "    \n",
    "    root = []\n",
    "    for node in graph.nodes: \n",
    "        if len(list(graph.predecessors(node)))==0:\n",
    "            root.append(node)\n",
    "    \n",
    "    intervention_node = np.random.choice([node for node in graph.nodes if node not in root], size=1)[0]\n",
    "    \n",
    "    if nx.has_path(graph, root[0], intervention_node):\n",
    "        print(root[0] + ' and ' + intervention_node + \" are in the same path.\")\n",
    "        index += 1\n",
    "    \n",
    "    data = generate_data_with_parametric_intervention(DAG =graph,n=n, secondInterventionNode=intervention_node, rootStartIntervention=n-2000, rootEndIntervention=n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d29c31-4a65-4b85-b564-a7ccff14858c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
